---
title: "Preliminary Analysis"
date-modified: "today"
subtitle: "Bias in PERSUADE"
format: pdf
code-fold: false
code-overflow: wrap
editor: 
  markdown: 
    wrap: 80
---

```{r, message = FALSE, warning = FALSE}
library(sjPlot) # HTML tables
library(lme4) # multi-level models
library(car) # level names in contrasts: contr.Sum
library(emmeans) # marginal means; interaction plots
library(performance) # quick ICC, AIC, etc.
library(tidyverse) # dyplr, forcats, ggplot2
library(ggthemes) # color palette for 15+ classes

df <- read.csv("../data/persuade_corpus.csv",
               na.strings = c("", " ", "NA")) %>% 
  select(-c(full_text, X, assignment, source_text)) %>%
  mutate_if(is.character, as.factor) %>%
  
  # drop American Indian/Alaskan Native group because there are < 200 samples
  filter(race_ethnicity != "American Indian/Alaskan Native") %>%
  
  # remove unused levels (American Indian)
  droplevels() %>% 
  
  # simplify level and variable names
  mutate(
    race=fct_recode(race_ethnicity,
                    asian="Asian/Pacific Islander",
                    black="Black/African American", 
                    hisp="Hispanic/Latino",
                    other="Two or more races/Other",
                    white="White")
    ) %>% 
  
  # collapse NaNs into negative level of binary factors
  mutate(
    is_ell=fct_collapse(addNA(ell), No = c("No", NA), Yes = "Yes"),
    is_disadvantaged=fct_collapse(addNA(economically_disadvantaged),
                                  No = c("Not economically disadvantaged", NA),
                                  Yes = "Economically disadvantaged"),
    has_disability=fct_collapse(addNA(student_disability_status),
                                  No = c("Not identified as having disability", NA),
                                  Yes = "Identified as having disability")
    ) %>% 
  
  # set the first level, which will be used as "reference"
  mutate(
    is_disadvantaged=fct_relevel(is_disadvantaged, "No"),
    has_disability=fct_relevel(has_disability, "No"),
  )

# configure contrasts for race and source
options(decorate.contr.Sum = c("", ""))
contrasts(df$race) = contr.Sum(levels(df$race))
contrasts(df$source) = contr.Sum(levels(df$source))

summary(df)
```

```{r}
eval_model <- function(mod) {
  print(performance(mod))
  print(tab_model(mod,
                  p.adjust="HB",
                  show.aic=TRUE,
                  show.re.var=TRUE,
                  # show.reflvl=TRUE,
                  prefix.labels="varname"
                  ))
}
```

```{r}
mod.null <-lmer(holistic_score_adjudicated ~ 1 + (1|prompt_name), data=df)
eval_model(mod.null)
```


# Simple model with just race

```{r}
mod.race <-lmer(holistic_score_adjudicated
                ~ race
                + (1|prompt_name),
                data=df
                )
eval_model(mod.race)
```

# All fixed effects

```{r}
mod.all_fixed_effects <- lmer(holistic_score_adjudicated 
                              ~ race
                              + grade # -7 to AIC (deviance test sig.)
                              + is_disadvantaged
                              + is_ell
                              + has_disability 
                              # + source # slightly improves model fit, but is not of interest
                              + gender
                              + (1|prompt_name),
                              data=df
                              )
eval_model(mod.all_fixed_effects)
```

### Why is grade not a good predictor?

```{r, fig.height=8}
df %>%
  summarize(
    Score = mean(holistic_score_adjudicated),
    SD.Score = sd(holistic_score_adjudicated),
    N = n(),
    ELLs = sum(as.numeric(is_ell)),
    Disability = sum(as.numeric(has_disability)),
    Disadvantaged = sum(as.numeric(is_disadvantaged)),
    .by=c(prompt_name, grade)
    ) %>%
  arrange(prompt_name, grade) %>%
  print()

df %>%
  add_count(grade, prompt_name, name="grade_prompt_n") %>%  
  add_count(grade, name="grade_n") %>% 
  add_count(prompt_name, name="prompt_n") %>%
  ggplot(aes(x=factor(grade), y=holistic_score_adjudicated, color=prompt_name)) +
    geom_violin(scale = "count",
                linewidth=0.75,
                position=position_dodge(width=0.75, preserve="total")) +
    stat_summary(fun=mean,
                 geom="line",
                 linewidth=1,
                 alpha=0.5,
                 lineend="butt",
                 linejoin="round",
                 position=position_dodge(width=0.75, preserve="total"),
                 aes(group=prompt_name)) +
    stat_summary(fun=mean,
                 geom="point",
                 alpha=0.5,
                 position=position_dodge(width=0.75, preserve="total"),
                 aes(shape=task, size=grade_prompt_n, group=prompt_name, color=prompt_name)) +
    scale_size(range=c(3,10)) +
    guides(
         # size="none",
         shape=guide_legend(title.position="top", title="Task", nrow=2),
         size=guide_legend(title.position="top", title="Count", nrow=4),
         color=guide_legend(title.position="top", title="Prompt", nrow=5)
           ) +
    labs(x="Grade", y="Holistic Score") +
    theme_clean() +
    scale_color_tableau(palette="Tableau 20") +
    theme(legend.title.align=0.5,
          legend.position = "bottom")

ggsave("../results/prompt_grade_violin.png")
```


# Search for interactions

We drop grade because it was not significant, but we test for an interaction between grade and ell. We might expect interactions: race\*ses, race\*ell, and race\*disability.

```{r}
mod.interactions <- lmer(holistic_score_adjudicated 
                         ~ race
                         + is_disadvantaged
                         + is_ell
                         + has_disability 
                         + gender
                         # + grade # increases AIC
                         # + race*is_disadvantaged # increases AIC
                         + race*is_ell
                         # + race*has_disability # increases AIC
                         # + race*source # increases AIC
                         # + race*gender # increases AIC
                         # + race*grade # increases AIC
                         + is_disadvantaged*has_disability
                         + is_disadvantaged*is_ell
                         + has_disability*is_ell
                         # + gender*has_disability # increases AIC
                         # + gender*is_disadvantaged # increases AIC
                         # + gender*is_ell # small decrease (-1) to AIC
                         + (1|prompt_name),
                         data=df
                         )
eval_model(mod.interactions)
```

# Search for random slopes

There are no good random slopes.

```{r}
mod.final <- mod.interactions
```


```{r}
emmip(mod.final, race~is_ell, mode = "asymp")
emmip(mod.final, is_disadvantaged~has_disability, mode = "asymp")
emmip(mod.final, is_disadvantaged~is_ell, mode = "asymp")
emmip(mod.final, has_disability~is_ell, mode = "asymp")
```

```{r}
coefs <- summary(mod.final)$coefficients
cat(rownames(coefs), sep="\", \"")
labels <- c("(Intercept)", "Asian/Pacific Islander", "Black/African American", "Hispanic/Latino", "Two or more races/Other", "Economically disadvantaged", "English language learner", "Identified as having disability", "Male", "Asian/Pacific Islander:English language learner", "Black/African American:English language learner", "Hispanic/Latino:English language learner", "Two or more races/Other:English language learner", "Economically disadvantaged:Identified as having disability", "English language learner:Economically disadvantaged", "English language learner:Identified as having disability", "English language learner:Male")

```


```{r, eval=FALSE}
tab_model(mod.final, 
          title = "Essay Scores Regressed on Demographic Variables",
          dv.labels = "Holistic Score",
          pred.labels = labels,
          emph.p = TRUE,
          p.adjust = "BH",
          # show.reflvl=TRUE,
          show.re.var=TRUE,
          file="../results/RQ1.html"
          )
```

